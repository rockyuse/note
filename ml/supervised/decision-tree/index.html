<!DOCTYPE html>
<html lang="zh_TW">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/note/shell.png" />
    

    <title>
        
          Decision Tree - kaiiiz/note
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/note/css/book.css">

    
<script src="/note/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
    
    <!-- katex -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">

    
<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-112717568-5', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 4.2.0"></head>

<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/note/">
    <img src="/note/shell.png">
    <span>KAIIIZ/NOTE</span>
  </a>
</div>
    <div class="book-menu">
  <ul>
<li><a href="/note">Home</a></li>
</ul>
<h2 id="osdi">OSDI</h2>
<ul>
<li><a href="/note/osdi/0-intro">Introduction</a></li>
<li><a href="/note/osdi/0-memory-map">Memory Map</a></li>
<li><a href="/note/osdi/1-env">Environment</a></li>
<li>Lab1
<ul>
<li><a href="/note/osdi/2-basic-init">Basic Initialization</a></li>
<li><a href="/note/osdi/3-uart">UART</a></li>
<li><a href="/note/osdi/4-mini-uart">Mini UART</a></li>
<li><a href="/note/osdi/5-simple-shell">Simple Shell</a></li>
</ul>
</li>
<li>Lab2
<ul>
<li><a href="/note/osdi/6-mailbox">Mailbox</a></li>
<li><a href="/note/osdi/7-pl011-uart">PL011 UART</a></li>
<li><a href="/note/osdi/8-frame-buffer">Frame Buffer</a></li>
<li><a href="/note/osdi/9-loadimg">3rd Bootloader</a></li>
</ul>
</li>
</ul>
<h2 id="parallel-programming">Parallel Programming</h2>
<ul>
<li><a href="/note/pp/shared-memory">Shared Memory</a></li>
<li>Pthread
<ul>
<li><a href="/note/pp/pthread/basic">Basic</a></li>
<li><a href="/note/pp/pthread/sync">Synchronization</a></li>
<li><a href="/note/pp/pthread/advanced">Advanced</a></li>
<li><a href="/note/pp/pthread/thread-pool">Thread Pool</a></li>
</ul>
</li>
<li>OpenMP
<ul>
<li><a href="/note/pp/openmp/basic">Basic</a></li>
<li><a href="/note/pp/openmp/worksharing-constructs">Worksharing Constructs</a></li>
<li><a href="/note/pp/openmp/synchronization">Synchronization</a></li>
<li><a href="/note/pp/openmp/variable-scope">Variable Scope</a></li>
</ul>
</li>
<li>MPI
<ul>
<li><a href="/note/pp/mpi/basic">Basic</a></li>
<li><a href="/note/pp/mpi/p2p-comm">Point-to-Point Comm.</a></li>
<li><a href="/note/pp/mpi/collective-comm">Collective Comm.</a></li>
<li><a href="/note/pp/mpi/consolidating-data">Consolidating Data</a></li>
<li><a href="/note/pp/mpi/additional-topics">Additional Topics</a></li>
</ul>
</li>
<li><a href="/note/pp/cuda">CUDA</a></li>
<li><a href="/note/pp/opencl">OpenCL</a></li>
</ul>
<h2 id="machine-learning">Machine Learning</h2>
<ul>
<li>Supervised Learning
<ul>
<li><a href="/note/ml/supervised/naive-bayes">Naive Bayes</a></li>
<li><a href="/note/ml/supervised/decision-tree">Decision Tree</a></li>
<li><a href="/note/ml/supervised/random-forest">Random Forest</a></li>
<li><a href="/note/ml/supervised/linear-regression">Linear Regression</a></li>
<li><a href="/note/ml/supervised/logistic-regression">Logistic Regression</a></li>
</ul>
</li>
<li>Deep Learning
<ul>
<li><a href="/note/ml/deep/backpropagation">Backpropagation</a></li>
</ul>
</li>
</ul>
<h2 id="network-services-adm">Network Services Adm.</h2>
<ul>
<li>Containers
<ul>
<li><a href="/note/na/lxc">LXC</a></li>
</ul>
</li>
<li>DNS Server
<ul>
<li><a href="/note/na/dns-server/intro">Introduction</a></li>
<li><a href="/note/na/dns-server/bind">BIND</a></li>
<li><a href="/note/na/dns-server/delegation+slave">Delegation &amp; Slave</a></li>
<li><a href="/note/na/dns-server/logging">Logging</a></li>
<li><a href="/note/na/dns-server/view">View</a></li>
<li><a href="/note/na/dns-server/security">Security</a></li>
</ul>
</li>
<li><a href="/note/na/dhcp-server">DHCP Server</a></li>
<li><a href="/note/na/firewall+nat-server">Firewall &amp; NAT Server</a></li>
<li><a href="/note/na/ftp-server+openldap">FTP with LDAP-Backend</a></li>
<li><a href="/note/na/http-proxy">HTTP Proxy</a></li>
<li>Mail Server
<ul>
<li><a href="/note/na/mail-server/mta+mra">MTA、MRA</a></li>
<li><a href="/note/na/mail-server/security">Security</a></li>
<li><a href="/note/na/mail-server/anti-scam">Anti-Scam</a></li>
<li><a href="/note/na/mail-server/anti-spam">Anti-Spam</a></li>
<li><a href="/note/na/mail-server/webmail+alias">Webmail、Alias</a></li>
</ul>
</li>
</ul>

</div>


<script src="/note/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="decision-tree">Decision Tree</h1>
<p><a href="/note/ml/supervised/decision-tree/sample_submission.csv">sample_submission.csv</a><br>
<a href="/note/ml/supervised/decision-tree/X_test.csv">X_test.csv</a><br>
<a href="/note/ml/supervised/decision-tree/X_train.csv">X_train.csv</a><br>
<a href="/note/ml/supervised/decision-tree/y_train.csv">y_train.csv</a></p>
<h2 id="目錄架構">目錄架構</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── census</span><br><span class="line">│   ├── data_preprocess.py</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">├── census_dt.py</span><br><span class="line">├── data</span><br><span class="line">│   ├── sample_submission.csv</span><br><span class="line">│   ├── X_test.csv</span><br><span class="line">│   ├── X_train.csv</span><br><span class="line">│   └── y_train.csv</span><br><span class="line">└── model</span><br><span class="line">    ├── decision_tree.py</span><br><span class="line">    └── __init__.py</span><br></pre></td></tr></table></figure>
<h2 id="主程式">主程式</h2>
<p>census_dt.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> census.data_preprocess <span class="keyword">import</span> CensusData</span><br><span class="line"><span class="keyword">from</span> model.decision_tree <span class="keyword">import</span> DecisionTree</span><br><span class="line"></span><br><span class="line">trees = []</span><br><span class="line">accuracies = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate</span><span class="params">(tree, df)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">holdoutValidation</span><span class="params">(df)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kFoldCrossValidation</span><span class="params">(df, K)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictLabel</span><span class="params">(tree, df)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    project_dir = os.path.dirname(os.path.realpath(__file__))</span><br><span class="line">    train_fp = project_dir + <span class="string">'/data/X_train.csv'</span></span><br><span class="line">    label_fp = project_dir + <span class="string">'/data/y_train.csv'</span></span><br><span class="line">    test_fp = project_dir + <span class="string">'/data/X_test.csv'</span></span><br><span class="line">    <span class="comment"># preprocess data</span></span><br><span class="line">    census_data = CensusData(train_fp, label_fp, test_fp)</span><br><span class="line">    census_data.handle_missing_data()</span><br><span class="line">    census_data.shuffle_data()</span><br><span class="line">    <span class="comment"># validation</span></span><br><span class="line">    print(<span class="string">"1) Holdout validation with train/test:7/3"</span>)</span><br><span class="line">    holdoutValidation(census_data.train_df)</span><br><span class="line">    print(<span class="string">"\n2) K-fold cross-validation with K=3"</span>)</span><br><span class="line">    kFoldCrossValidation(census_data.train_df, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># choose best tree to predict test set</span></span><br><span class="line">    <span class="keyword">global</span> trees, accuracies</span><br><span class="line">    best_tree_idx = accuracies.index(max(accuracies))</span><br><span class="line">    best_tree = trees[best_tree_idx]</span><br><span class="line">    predictLabel(best_tree, census_data.test_df)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<ol>
<li>將 data 的路徑定義好</li>
<li>丟進 CensusData 做預處理</li>
<li>處理 Data 中缺失的欄位</li>
<li>打亂 Train Data</li>
<li>透過 holdout validation 以及 k-fold cross validation 檢驗正確性</li>
<li>選出正確率最高的 Tree 對 test set 猜測答案</li>
</ol>
<p>holdoutValidation:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">holdoutValidation</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="comment"># split train / validation data to 7 : 3</span></span><br><span class="line">    dataSize = len(df)</span><br><span class="line">    train_df = df.head(dataSize * <span class="number">7</span> // <span class="number">10</span>)</span><br><span class="line">    validation_df = df.tail(dataSize - dataSize * <span class="number">7</span> // <span class="number">10</span>)</span><br><span class="line">    <span class="comment"># train model</span></span><br><span class="line">    tree = DecisionTree(train_df)</span><br><span class="line">    <span class="comment"># validation</span></span><br><span class="line">    cm = validate(tree, validation_df)</span><br><span class="line">    accuracy = (cm[<span class="number">0</span>][<span class="number">0</span>] + cm[<span class="number">1</span>][<span class="number">1</span>]) / cm.values.sum()</span><br><span class="line">    print(cm)</span><br><span class="line">    print(<span class="string">"accuracy:"</span>, accuracy)</span><br><span class="line">    <span class="comment"># store result</span></span><br><span class="line">    <span class="keyword">global</span> trees, accuracies</span><br><span class="line">    trees.append(tree)</span><br><span class="line">    accuracies.append(accuracy)</span><br></pre></td></tr></table></figure>
<ol>
<li>切割 Data 為 train:validation = 7:3</li>
<li>Train Model</li>
<li>透過 Validation Data 驗證正確性</li>
</ol>
<p>kFoldCrossValidation:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kFoldCrossValidation</span><span class="params">(df, K)</span>:</span></span><br><span class="line">    partSize = len(df) // K</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">        <span class="comment"># split train / validation data to K part</span></span><br><span class="line">        validation_df = df[i * partSize: (i + <span class="number">1</span>) * partSize]</span><br><span class="line">        train_df = df.drop(validation_df.index)</span><br><span class="line">        validation_df.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        train_df.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># train model</span></span><br><span class="line">        tree = DecisionTree(train_df)</span><br><span class="line">        <span class="comment"># test model</span></span><br><span class="line">        cm = validate(tree, validation_df)</span><br><span class="line">        accuracy = (cm[<span class="number">0</span>][<span class="number">0</span>] + cm[<span class="number">1</span>][<span class="number">1</span>]) / cm.values.sum()</span><br><span class="line">        print(<span class="string">'-- fold'</span>, i)</span><br><span class="line">        print(cm)</span><br><span class="line">        print(<span class="string">"accuracy:"</span>, accuracy)</span><br><span class="line">        <span class="comment"># store result</span></span><br><span class="line">        <span class="keyword">global</span> trees, accuracies</span><br><span class="line">        trees.append(tree)</span><br><span class="line">        accuracies.append(accuracy)</span><br></pre></td></tr></table></figure>
<ol>
<li>做 K 次分割不同區段的 train 及 validation data</li>
<li>Train Model</li>
<li>透過不同區段的 Validation Data 驗證正確性</li>
</ol>
<p>validate:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate</span><span class="params">(tree, df)</span>:</span></span><br><span class="line">    cm = np.zeros(shape=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        ans = row.Category</span><br><span class="line">        predict = tree.predict(row)</span><br><span class="line">        cm[ans][predict] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(data=cm)</span><br></pre></td></tr></table></figure>
<ol>
<li>紀錄並回傳 Confusion matrix</li>
</ol>
<h2 id="data-preprocessing">Data Preprocessing</h2>
<p>census / data_preprocess.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CensusData</span><span class="params">()</span>:</span></span><br><span class="line">    train_df = <span class="literal">None</span></span><br><span class="line">    test_df = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, train_fp, label_fp, test_fp)</span>:</span></span><br><span class="line">        train_df = pd.read_csv(train_fp)</span><br><span class="line">        train_df.set_index(<span class="string">'Id'</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># add label to end of train data</span></span><br><span class="line">        label_df = pd.read_csv(label_fp)</span><br><span class="line">        label_df.set_index(<span class="string">'Id'</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        df = pd.merge(train_df, label_df, on=<span class="string">'Id'</span>)</span><br><span class="line">        <span class="comment"># strip all string data</span></span><br><span class="line">        df_obj = df.select_dtypes([<span class="string">'object'</span>])</span><br><span class="line">        df[df_obj.columns] = df_obj.apply(<span class="keyword">lambda</span> x: x.str.strip())</span><br><span class="line">        self.train_df = df</span><br><span class="line"></span><br><span class="line">        test_df = pd.read_csv(test_fp)</span><br><span class="line">        test_df.set_index(<span class="string">'Id'</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># strip all string data</span></span><br><span class="line">        df_obj = test_df.select_dtypes([<span class="string">'object'</span>])</span><br><span class="line">        test_df[df_obj.columns] = df_obj.apply(<span class="keyword">lambda</span> x: x.str.strip())</span><br><span class="line">        self.test_df = test_df</span><br><span class="line"></span><br><span class="line">    <span class="comment"># fill missing data to most frequently value (because features of missing data are all categories)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle_missing_data</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.train_df = self.train_df.replace(&#123;<span class="string">'?'</span>: np.nan&#125;)</span><br><span class="line">        self.train_df = self.train_df.fillna(self.train_df.mode().iloc[<span class="number">0</span>])</span><br><span class="line">        self.test_df = self.test_df.replace(&#123;<span class="string">'?'</span>: np.nan&#125;)</span><br><span class="line">        self.test_df = self.test_df.fillna(self.test_df.mode().iloc[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shuffle_data</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.train_df = self.train_df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>建構式：</p>
<ol>
<li>把 Label 放在 Train Dataframe 的最後一個 Column</li>
<li>同一 string 的 data，必免空格導致誤判</li>
<li>儲存 Test Data</li>
</ol>
<p>handle_missing_data:</p>
<ol>
<li>把 train data 與 test data 中的缺失項找出 (先換成 nan，再全部 replace)</li>
<li>把缺失項換成出現頻率最高的值 (因為缺失項都為非連續的欄位，所以不考慮連續情況)</li>
</ol>
<h2 id="資料結構設計">資料結構設計</h2>
<p>Decision Tree 的框架設計為：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tree &#x3D; &#123;</span><br><span class="line">  &quot;feature&quot;: &#123;</span><br><span class="line">      &quot;question&quot;: &#123;</span><br><span class="line">          &quot;feature&quot;: &#123;</span><br><span class="line">              ...</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      &quot;question&quot;: &#123;</span><br><span class="line">          ...</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>舉例來說：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tree &#x3D; &#123;</span><br><span class="line">  &quot;age&quot;: &#123;</span><br><span class="line">      &quot;&gt;10&quot;: &#123;</span><br><span class="line">          &quot;relationship&quot;: &#123;</span><br><span class="line">              &quot;&#x3D;&#x3D; Husband&quot;: &#123;</span><br><span class="line"></span><br><span class="line">              &#125;,</span><br><span class="line">              ...</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      &quot;&lt;&#x3D;10&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同時這個 Tree 支援 multiple branch，在可分類(非連續)的欄位會建立所有可支援的 branch，在連續的欄位會有 &gt;, &lt;= 區分兩種範圍</p>
<h2 id="model">Model</h2>
<p>model / decision_tree.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecisionTree</span><span class="params">()</span>:</span></span><br><span class="line">    COLUMNS = <span class="literal">None</span></span><br><span class="line">    tree = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, df, max_depth=<span class="number">5</span>, random_feature=None)</span>:</span></span><br><span class="line">        data = df.values  <span class="comment"># numpy n-d array</span></span><br><span class="line">        self.COLUMNS = df.columns</span><br><span class="line">        self.tree = self.buildTree(</span><br><span class="line">            data=data, max_depth=max_depth, random_feature=random_feature)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">guess</span><span class="params">(self, tree, entry)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, entry)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildTree</span><span class="params">(self, data, depth=<span class="number">0</span>, max_depth=<span class="number">5</span>, random_feature=None)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># find feature of highest Information Gain (lowest Remainder)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detBestFeature</span><span class="params">(self, data, levels)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calcCategoryRem</span><span class="params">(self, data, feature_idx, level)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calcContinousRem</span><span class="params">(self, data, feature_idx, split_value)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calcEntropy</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="comment"># utility functions</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">splitContinuous</span><span class="params">(self, data, col_idx, value)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getUniqueLevels</span><span class="params">(self, data, random_feature=None)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classifyData</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checkPurity</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>建構式：</p>
<ol>
<li>把 pandas dataframe 轉為 numpy nd-array</li>
<li>取出 COLUMNS 的名字</li>
<li>遞迴建立 Tree</li>
</ol>
<p>分為 4 個部份：</p>
<ul>
<li>建立樹</li>
<li>選擇最佳分支</li>
<li>helper function</li>
<li>預測答案</li>
</ul>
<h3 id="建立樹">建立樹</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildTree</span><span class="params">(self, data, depth=<span class="number">0</span>, max_depth=<span class="number">5</span>, random_feature=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.checkPurity(data) <span class="keyword">or</span> len(data) &lt; <span class="number">2</span> <span class="keyword">or</span> (depth == max_depth):</span><br><span class="line">        <span class="keyword">return</span> self.classifyData(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        depth += <span class="number">1</span></span><br><span class="line">        <span class="comment"># levels = &#123; feature_idx: unique_level &#125;</span></span><br><span class="line">        levels = self.getUniqueLevels(data, random_feature)</span><br><span class="line">        best_feature = self.detBestFeature(data, levels)</span><br><span class="line">        best_feature_data = data[:, best_feature[<span class="string">'idx'</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># build tree</span></span><br><span class="line">        best_feature_name = self.COLUMNS[best_feature[<span class="string">'idx'</span>]]</span><br><span class="line">        tree = &#123;best_feature_name: &#123;&#125;&#125;</span><br><span class="line">        qnode = tree[best_feature_name]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> best_feature[<span class="string">'type'</span>] == int:</span><br><span class="line">            best_split = best_feature[<span class="string">'split'</span>]</span><br><span class="line">            data_above = data[best_feature_data &gt; best_split]</span><br><span class="line">            data_below = data[best_feature_data &lt;= best_split]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> len(data_below) == <span class="number">0</span> <span class="keyword">or</span> len(data_above) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> self.classifyData(data)</span><br><span class="line"></span><br><span class="line">            question_above = <span class="string">"&gt; &#123;&#125;"</span>.format(best_split)</span><br><span class="line">            question_below = <span class="string">"&lt;= &#123;&#125;"</span>.format(best_split)</span><br><span class="line">            ans_above = self.buildTree(</span><br><span class="line">                data=data_above, depth=depth, random_feature=random_feature)</span><br><span class="line">            ans_below = self.buildTree(</span><br><span class="line">                data=data_below, depth=depth, random_feature=random_feature)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> ans_above == ans_below:</span><br><span class="line">                tree = ans_above</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                qnode[question_above] = ans_above</span><br><span class="line">                qnode[question_below] = ans_below</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            best_catories = best_feature[<span class="string">'categories'</span>]</span><br><span class="line">            <span class="keyword">for</span> category <span class="keyword">in</span> best_catories:</span><br><span class="line">                level_data = data[best_feature_data == category]</span><br><span class="line">                question = <span class="string">"== &#123;&#125;"</span>.format(category)</span><br><span class="line">                qnode[question] = self.buildTree(</span><br><span class="line">                    data=level_data, depth=depth, random_feature=random_feature)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># for other possible branch not exist in train data set</span></span><br><span class="line">            question = <span class="string">"!= possible"</span></span><br><span class="line">            qnode[question] = self.classifyData(data)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure>
<ol>
<li>檢查 Base case
<ul>
<li>data 的 Purity，若 data 為單一的 label 就直接 classify Data</li>
<li>若資料量剩一筆，直接 classify Data</li>
<li>若遞迴深度到達最大深度，classify Data</li>
</ul>
</li>
<li>算出 data 中各個 feature 的 unique levels</li>
<li>選出最佳的 feature 當作 root (Information Gain 最大的 feature)</li>
<li>best feature 分兩種情況
<ul>
<li>連續 (data 的 type 為 int)
<ul>
<li>對最佳的分割值做分割</li>
<li>若分割後 data 為空則直接 return classify Data</li>
<li>非空則建立 &gt;, &lt;= 的 branch</li>
<li>若分割後 above 與 below 的 data 相同則直接 return 其中一個，不再分割 branch</li>
</ul>
</li>
<li>非連續 (data 的 type 為 str)
<ul>
<li>對所有 category 都建一條 branch</li>
<li>再建一條如果所有 branch 都沒有 match 到的情況 (有可能 test data 的 category 不包含在 train data 中)</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="選擇最佳分支">選擇最佳分支</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find feature of highest Information Gain (lowest Remainder)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detBestFeature</span><span class="params">(self, data, levels)</span>:</span></span><br><span class="line">    ret_val = &#123;</span><br><span class="line">        <span class="string">'idx'</span>: <span class="number">7</span>,</span><br><span class="line">        <span class="string">'type'</span>: str,</span><br><span class="line">        <span class="string">'split'</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">'categories'</span>: []</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    min_remainder = <span class="number">2147483647</span></span><br><span class="line">    <span class="keyword">for</span> feature_idx, level <span class="keyword">in</span> levels.items():</span><br><span class="line">        column = data[:, feature_idx]</span><br><span class="line">        column_type = type(column[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> column_type == int:</span><br><span class="line">            <span class="keyword">for</span> split_value <span class="keyword">in</span> level:</span><br><span class="line">                remainder = self.calcContinousRem(</span><br><span class="line">                    data, feature_idx, split_value)</span><br><span class="line">                <span class="keyword">if</span> remainder &lt; min_remainder:</span><br><span class="line">                    min_remainder = remainder</span><br><span class="line">                    ret_val[<span class="string">'idx'</span>] = feature_idx</span><br><span class="line">                    ret_val[<span class="string">'type'</span>] = int</span><br><span class="line">                    ret_val[<span class="string">'split'</span>] = split_value</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            remainder = self.calcCategoryRem(data, feature_idx, level)</span><br><span class="line">            <span class="keyword">if</span> remainder &lt; min_remainder:</span><br><span class="line">                min_remainder = remainder</span><br><span class="line">                ret_val[<span class="string">'idx'</span>] = feature_idx</span><br><span class="line">                ret_val[<span class="string">'type'</span>] = str</span><br><span class="line">                ret_val[<span class="string">'categories'</span>] = level</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret_val</span><br></pre></td></tr></table></figure>
<ol>
<li>最佳的 feature 為 remainder 最小的 feature</li>
<li>兩種可能情況
<ul>
<li>連續
<ul>
<li>對所有可能的 split value (unique levels) 分割 data</li>
<li>計算這個分割的 remainder 若為最小就更新最佳的 feature</li>
</ul>
</li>
<li>非連續
<ul>
<li>對所有可能的 category 分割 data</li>
<li>計算 category 的 remainder 若為最小就更新最佳的 feature</li>
</ul>
</li>
</ul>
</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcCategoryRem</span><span class="params">(self, data, feature_idx, level)</span>:</span></span><br><span class="line">    remainder = <span class="number">0</span></span><br><span class="line">    column = data[:, feature_idx]</span><br><span class="line">    <span class="keyword">for</span> category <span class="keyword">in</span> level:</span><br><span class="line">        level_data = data[column == category]</span><br><span class="line">        partition_entropy = self.calcEntropy(level_data)</span><br><span class="line">        conditional_prob = len(level_data) / len(data)</span><br><span class="line">        remainder += partition_entropy * conditional_prob</span><br><span class="line">    <span class="keyword">return</span> remainder</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcContinousRem</span><span class="params">(self, data, feature_idx, split_value)</span>:</span></span><br><span class="line">    <span class="comment"># split 2 parts</span></span><br><span class="line">    data_below, data_above = self.splitContinuous(</span><br><span class="line">        data=data, col_idx=feature_idx, value=split_value)</span><br><span class="line">    <span class="comment"># calculate total entropy</span></span><br><span class="line">    p_data_below = len(data_below) / len(data)</span><br><span class="line">    p_data_above = len(data_above) / len(data)</span><br><span class="line">    remainder = (p_data_below * self.calcEntropy(data_below) +</span><br><span class="line">                    p_data_above * self.calcEntropy(data_above))</span><br><span class="line">    <span class="keyword">return</span> remainder</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEntropy</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    label_data = data[:, <span class="number">-1</span>]</span><br><span class="line">    _, counts = np.unique(label_data, return_counts=<span class="literal">True</span>)</span><br><span class="line">    probabilities = counts / counts.sum()</span><br><span class="line">    entropy = -sum(probabilities * np.log2(probabilities))</span><br><span class="line">    <span class="keyword">return</span> entropy</span><br></pre></td></tr></table></figure>
<ol>
<li>算出 entropy</li>
<li>計算條件機率</li>
</ol>
<h3 id="helper-function">helper function</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utility functions</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitContinuous</span><span class="params">(self, data, col_idx, value)</span>:</span></span><br><span class="line">    column = data[:, col_idx]</span><br><span class="line">    data_above = data[column &gt; value]</span><br><span class="line">    data_below = data[column &lt;= value]</span><br><span class="line">    <span class="keyword">return</span> data_below, data_above</span><br></pre></td></tr></table></figure>
<ol>
<li>分割上下兩段 data</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getUniqueLevels</span><span class="params">(self, data, random_feature=None)</span>:</span></span><br><span class="line">    levels = &#123;&#125;</span><br><span class="line">    _, n_cols = data.shape</span><br><span class="line">    column_indices = list(range(n_cols - <span class="number">1</span>))  <span class="comment"># except label</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> random_feature <span class="keyword">and</span> random_feature &lt;= len(column_indices):</span><br><span class="line">        column_indices = random.sample(</span><br><span class="line">            population=column_indices, k=random_feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col_idx <span class="keyword">in</span> column_indices:</span><br><span class="line">        col_data = data[:, col_idx]</span><br><span class="line">        col_unique = np.unique(col_data)</span><br><span class="line">        levels[col_idx] = col_unique</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> levels</span><br></pre></td></tr></table></figure>
<ol>
<li>算出 unique level</li>
<li>若 random forest 有要隨機選擇 feature 則隨機選擇 index</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyData</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    label_data = data[:, <span class="number">-1</span>]</span><br><span class="line">    unique_label, unique_counts = np.unique(label_data, return_counts=<span class="literal">True</span>)</span><br><span class="line">    idx = unique_counts.argmax()</span><br><span class="line">    <span class="keyword">return</span> unique_label[idx]</span><br></pre></td></tr></table></figure>
<ol>
<li>選擇 data 中出現頻率最高的 label</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkPurity</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    label_data = data[:, <span class="number">-1</span>]</span><br><span class="line">    label_unique = np.unique(label_data)</span><br><span class="line">    <span class="keyword">if</span> len(label_unique) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<ol>
<li>若 data 中只存在一種 label 則為 purity</li>
</ol>
<h3 id="預測答案">預測答案</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, entry)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.guess(self.tree, entry)</span><br></pre></td></tr></table></figure>
<ol>
<li>call guess 這個遞迴 function</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guess</span><span class="params">(self, tree, entry)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tree, dict):</span><br><span class="line">        <span class="keyword">return</span> tree</span><br><span class="line"></span><br><span class="line">    feature = list(tree.keys())[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> question, predict_ans <span class="keyword">in</span> tree[feature].items():</span><br><span class="line">        condition, value = question.split(<span class="string">" "</span>)</span><br><span class="line">        answer = predict_ans</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> condition == <span class="string">"=="</span> <span class="keyword">and</span> entry[feature] == value:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">elif</span> condition == <span class="string">"&lt;="</span> <span class="keyword">and</span> entry[feature] &lt;= float(value):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">elif</span> condition == <span class="string">"&gt;"</span> <span class="keyword">and</span> entry[feature] &gt; float(value):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(answer, dict):</span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> self.guess(answer, entry)</span><br></pre></td></tr></table></figure>
<ol>
<li>若 tree 直接為 label 則直接 return</li>
<li>選擇 tree 的 feature</li>
<li>對 feature 下的 question 做 parse</li>
<li>把 answer 設為 predict_ans (可能是一顆樹或是直接是 label)，若滿足條件則 break</li>
<li>如果 answer 是樹則遞迴下去找答案</li>
<li>若 answer 是 label 則直接 return</li>
</ol>
<h2 id="result">Result</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1) Holdout validation with train&#x2F;test:7&#x2F;3</span><br><span class="line">        0      1</span><br><span class="line">0  4779.0  390.0</span><br><span class="line">1   689.0  980.0</span><br><span class="line">accuracy: 0.8422053231939164</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">2) K-fold cross-validation with K&#x3D;3</span><br><span class="line">-- fold 0</span><br><span class="line">        0      1</span><br><span class="line">0  5372.0  403.0</span><br><span class="line">1   834.0  988.0</span><br><span class="line">accuracy: 0.8371725681189943</span><br><span class="line">-- fold 1</span><br><span class="line">        0       1</span><br><span class="line">0  5334.0   397.0</span><br><span class="line">1   802.0  1064.0</span><br><span class="line">accuracy: 0.8421745425825984</span><br><span class="line">-- fold 2</span><br><span class="line">        0       1</span><br><span class="line">0  5319.0   439.0</span><br><span class="line">1   761.0  1078.0</span><br><span class="line">accuracy: 0.8420429116756615</span><br></pre></td></tr></table></figure>

</div>


  <div class="book-comments">
    


    <div id="disqus_thread"></div>
    <script>
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://at881005.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>



  </div>



<script src="/note/js/book-post.js"></script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">

  <div class="author">

    <!-- Author image -->
    <div class="author-img">
      
        <figure class="avatar avatar-lg">
          <img src="/note/andy.png" alt="...">
        </figure>
      
    </div>

    <!-- Author title -->
    <div class="author-title">
      <div>Andy Zheng</div>
      <div>2020-03-17</div>
    </div>
  </div>

  
    <div class="divider"></div>

    <div class="link">
      

      <a class="tag-link" href="/note/tags/ML/" rel="tag">#ML</a>
    </div>
    
  

  <div class="divider"></div>
</div>
  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/note/js/book-toc.js"></script>

</div>
      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/note/js/book.js"></script>
